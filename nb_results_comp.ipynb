{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b6f656",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459c26e",
   "metadata": {},
   "source": [
    "## Corpus (all 40 odes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a7e01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "TRIADS: \n",
      "Total corpus comp (all 40 odes): \u001b[1;32m0.7789296914527603\u001b[0m\n",
      "Triads: Number of variables: 11379\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "STROPHES: \n",
      "Total corpus comp: \u001b[1;32m0.7256545951931218\u001b[0m\n",
      "Strophes: Number of variables: 3543\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "EPODES: \n",
      "Total corpus comp: \u001b[1;32m0.7833079934483543\u001b[0m\n",
      "Epodes: Number of variables: 3491\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.stats_comp import compatibility_corpus, compatibility_ratios_to_stats\n",
    "\n",
    "def count_leaves(obj):\n",
    "    \"\"\"Count all leaf (non-list) elements in a nested structure.\"\"\"\n",
    "    if isinstance(obj, list):\n",
    "        return sum(count_leaves(item) for item in obj)\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "all_ratio_sets_triads = compatibility_corpus('data/compiled/triads/')\n",
    "all_ratio_sets_strophes = compatibility_corpus('data/compiled/strophes/')\n",
    "all_ratio_sets_epodes = compatibility_corpus('data/compiled/epodes/')\n",
    "total_comp_triads = compatibility_ratios_to_stats(all_ratio_sets_triads)\n",
    "total_comp_strophes = compatibility_ratios_to_stats(all_ratio_sets_strophes)\n",
    "total_comp_epodes = compatibility_ratios_to_stats(all_ratio_sets_epodes)\n",
    "\n",
    "# Count total number of leaf values\n",
    "total_triads = sum(count_leaves(lst) for lst in all_ratio_sets_triads)\n",
    "total_strophes = sum(count_leaves(lst) for lst in all_ratio_sets_strophes)\n",
    "total_epodes = sum(count_leaves(lst) for lst in all_ratio_sets_epodes)\n",
    "\n",
    "print ('--------------------------------------------')\n",
    "print(f'TRIADS: \\nTotal corpus comp (all 40 odes): \\033[1;32m{total_comp_triads}\\033[0m')\n",
    "print(f'Triads: Number of variables: {total_triads}')\n",
    "print ('--------------------------------------------')\n",
    "\n",
    "print ('--------------------------------------------')\n",
    "print(f'STROPHES: \\nTotal corpus comp: \\033[1;32m{total_comp_strophes}\\033[0m')\n",
    "print(f'Strophes: Number of variables: {total_strophes}')\n",
    "print ('--------------------------------------------')\n",
    "\n",
    "print ('--------------------------------------------')\n",
    "print(f'EPODES: \\nTotal corpus comp: \\033[1;32m{total_comp_epodes}\\033[0m')\n",
    "print(f'Epodes: Number of variables: {total_epodes}')\n",
    "print ('--------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb91fb1",
   "metadata": {},
   "source": [
    "Let's also compute values for all individual odes and compare with their baselines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ddb385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "\u001b[1;32m1\u001b[0m\n",
      "ODE is01 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.75\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.73\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m2\u001b[0m\n",
      "ODE is02 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.82\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.79\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m3\u001b[0m\n",
      "ODE is04 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.76\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.74\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m4\u001b[0m\n",
      "ODE is05 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.78\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.78\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m5\u001b[0m\n",
      "ODE is06 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.80\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.80\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m6\u001b[0m\n",
      "ODE is07 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.81\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.79\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m7\u001b[0m\n",
      "ODE is08 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.72\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.73\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m8\u001b[0m\n",
      "ODE ne01 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.74\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.73\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m9\u001b[0m\n",
      "ODE ne02 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.75\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.72\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m10\u001b[0m\n",
      "ODE ne03 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.76\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.73\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m11\u001b[0m\n",
      "ODE ne04 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.70\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.69\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m12\u001b[0m\n",
      "ODE ne05 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.78\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.79\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m13\u001b[0m\n",
      "ODE ne06 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.79\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.79\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m14\u001b[0m\n",
      "ODE ne07 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.75\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.75\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m15\u001b[0m\n",
      "ODE ne08 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.81\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.79\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m16\u001b[0m\n",
      "ODE ne09 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.69\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.68\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m17\u001b[0m\n",
      "ODE ne10 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.73\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.73\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m18\u001b[0m\n",
      "ODE ne11 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.78\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.79\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m19\u001b[0m\n",
      "ODE ol01 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.74\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.73\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m20\u001b[0m\n",
      "ODE ol02 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.75\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.75\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m21\u001b[0m\n",
      "ODE ol03 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.80\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.79\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m22\u001b[0m\n",
      "ODE ol05 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.81\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.79\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m23\u001b[0m\n",
      "ODE ol06 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.75\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.73\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m24\u001b[0m\n",
      "ODE ol07 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.75\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.74\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m25\u001b[0m\n",
      "ODE ol08 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.74\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.74\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m26\u001b[0m\n",
      "ODE ol09 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.74\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.75\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m27\u001b[0m\n",
      "ODE ol10 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.73\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.74\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m28\u001b[0m\n",
      "ODE ol13 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.73\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.75\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m29\u001b[0m\n",
      "ODE ol14 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.79\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.82\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m30\u001b[0m\n",
      "ODE py01 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.76\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.74\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m31\u001b[0m\n",
      "ODE py02 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.74\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.73\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m32\u001b[0m\n",
      "ODE py03 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.74\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.74\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m33\u001b[0m\n",
      "ODE py04 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.71\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.69\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m34\u001b[0m\n",
      "ODE py05 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.76\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.75\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m35\u001b[0m\n",
      "ODE py06 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.75\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.72\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m36\u001b[0m\n",
      "ODE py08 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.75\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.75\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m37\u001b[0m\n",
      "ODE py09 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.74\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.74\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m38\u001b[0m\n",
      "ODE py10 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.75\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.74\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m39\u001b[0m\n",
      "ODE py11 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.76\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.74\u001b[0m\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "\u001b[1;32m40\u001b[0m\n",
      "ODE py12 TRIADS:\n",
      "Ode comp: \u001b[1;32m0.74\u001b[0m\n",
      "Baseline (prose) comp: \u001b[1;32m0.75\u001b[0m\n",
      "--------------------------------------------\n",
      "0.8158295281582952\n",
      "0.8173076923076923\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "from src.stats_comp import compatibility_canticum, compatibility_ratios_to_stats\n",
    "from results import victory_odes\n",
    "\n",
    "in_folder_odes_triads = \"data/compiled/triads/\"\n",
    "in_folder_baselines_triads = \"data/compiled/baselines/triads/prose/\"\n",
    "\n",
    "ode_comp_scores = {}\n",
    "baseline_prose_comp_scores = {}\n",
    "index = 0\n",
    "for ode in victory_odes:\n",
    "\n",
    "    index += 1\n",
    "\n",
    "    if ode[:2] == 'py':\n",
    "        ode_path = os.path.join(in_folder_odes_triads, \"ht_pythians_triads.xml\")\n",
    "    elif ode[:2] == 'ne':\n",
    "        ode_path = os.path.join(in_folder_odes_triads, \"ht_nemeans_triads.xml\")\n",
    "    elif ode[:2] == 'ol':\n",
    "        ode_path = os.path.join(in_folder_odes_triads, \"ht_olympians_triads.xml\")\n",
    "    elif ode[:2] == 'is':\n",
    "        ode_path = os.path.join(in_folder_odes_triads, \"ht_isthmians_triads.xml\")\n",
    "\n",
    "    baseline_path = os.path.join(in_folder_baselines_triads, f\"baseline_prose_{ode}.xml\")\n",
    "    \n",
    "    ode_ratios = compatibility_canticum(ode_path, ode)\n",
    "    baseline_ratios = compatibility_canticum(baseline_path, ode)\n",
    "    \n",
    "    ode_comp = compatibility_ratios_to_stats(ode_ratios)\n",
    "    baseline_comp = compatibility_ratios_to_stats(baseline_ratios)\n",
    "\n",
    "    ode_comp_scores[ode] = ode_comp\n",
    "    baseline_prose_comp_scores[ode] = baseline_comp\n",
    "\n",
    "    print ('--------------------------------------------')\n",
    "    print(f'\\033[1;32m{index}\\033[0m')\n",
    "    print(f'ODE {ode} TRIADS:')\n",
    "    print(f'Ode comp: \\033[1;32m{ode_comp:.2f}\\033[0m')\n",
    "    print(f'Baseline (prose) comp: \\033[1;32m{baseline_comp:.2f}\\033[0m')\n",
    "    print ('--------------------------------------------')\n",
    "\n",
    "print(max(ode_comp_scores.values()))\n",
    "print(max(baseline_prose_comp_scores.values()))\n",
    "\n",
    "for (ode_key, ode_value), (baseline_key, baseline_value) in zip(ode_comp_scores.items(), baseline_prose_comp_scores.items()):\n",
    "    if ode_value < baseline_value:\n",
    "        print(f'Baseline better than ode for {ode_key}: ode {ode_value} < baseline {baseline_value}')\n",
    "\n",
    "\n",
    "# with open('results.py', 'a', encoding='utf-8') as f:\n",
    "#     content = ',\\n'.join(f\"\\t'{key}': {value}\" for key, value in ode_comp_scores.items())\n",
    "#     f.write(f'ode_comp_scores = {{\\n{content}\\n}}')\n",
    "\n",
    "#     baseline_content = ',\\n'.join(f\"\\t'{key}': {value}\" for key, value in baseline_prose_comp_scores.items())\n",
    "#     f.write(f'\\nbaseline_prose_comp_scores = {{\\n{baseline_content}\\n}}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a823ce",
   "metadata": {},
   "source": [
    "## Groupings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37534720",
   "metadata": {},
   "source": [
    "### By collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d64a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.stats_comp import compatibility_play, compatibility_ratios_to_stats\n",
    "\n",
    "def collection_stats(collection: str):\n",
    "    all_ratio_sets_triads = compatibility_play(f'data/compiled/triads/ht_{collection}_triads.xml')\n",
    "    all_ratio_sets_strophes = compatibility_play(f'data/compiled/strophes/ht_{collection}_strophes.xml')\n",
    "    all_ratio_sets_epodes = compatibility_play(f'data/compiled/epodes/ht_{collection}_epodes.xml')\n",
    "\n",
    "    total_comp_triads = compatibility_ratios_to_stats(all_ratio_sets_triads)\n",
    "    total_comp_strophes = compatibility_ratios_to_stats(all_ratio_sets_strophes)\n",
    "    total_comp_epodes = compatibility_ratios_to_stats(all_ratio_sets_epodes)\n",
    "\n",
    "    return total_comp_triads, total_comp_strophes, total_comp_epodes\n",
    "\n",
    "total_comp_triads_olympians, total_comp_strophes_olympians, total_comp_epodes_olympians = collection_stats('olympians')\n",
    "total_comp_triads_pythians, total_comp_strophes_pythians, total_comp_epodes_pythians = collection_stats('pythians')\n",
    "total_comp_triads_nemeans, total_comp_strophes_nemeans, total_comp_epodes_nemeans = collection_stats('nemeans')\n",
    "total_comp_triads_isthmians, total_comp_strophes_isthmians, total_comp_epodes_isthmians = collection_stats('isthmians')\n",
    "\n",
    "print ('--------------------------------------------')\n",
    "print(f'OLYMPIANS')\n",
    "print(f'Total comp triads: \\033[1;32m{total_comp_triads_olympians}\\033[0m')\n",
    "print(f'Total comp strophes: \\033[1;32m{total_comp_strophes_olympians}\\033[0m')\n",
    "print(f'Total comp epodes: \\033[1;32m{total_comp_epodes_olympians}\\033[0m')\n",
    "\n",
    "print ('--------------------------------------------')\n",
    "print(f'PYTHIANS')\n",
    "print(f'Total comp triads: \\033[1;32m{total_comp_triads_pythians}\\033[0m')\n",
    "print(f'Total comp strophes: \\033[1;32m{total_comp_strophes_pythians}\\033[0m')\n",
    "print(f'Total comp epodes: \\033[1;32m{total_comp_epodes_pythians}\\033[0m')\n",
    "\n",
    "print ('--------------------------------------------')\n",
    "print(f'NEMEANS')\n",
    "print(f'Total comp triads: \\033[1;32m{total_comp_triads_nemeans}\\033[0m')\n",
    "print(f'Total comp strophes: \\033[1;32m{total_comp_strophes_nemeans}\\033[0m')\n",
    "print(f'Total comp epodes: \\033[1;32m{total_comp_epodes_nemeans}\\033[0m')\n",
    "\n",
    "print ('--------------------------------------------')\n",
    "print(f'ISTHMIANS')\n",
    "print(f'Total comp triads: \\033[1;32m{total_comp_triads_isthmians}\\033[0m')\n",
    "print(f'Total comp strophes: \\033[1;32m{total_comp_strophes_isthmians}\\033[0m')\n",
    "print(f'Total comp epodes: \\033[1;32m{total_comp_epodes_isthmians}\\033[0m')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d4f4e",
   "metadata": {},
   "source": [
    "### By strophicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3be6a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triad Responsion Counts:\n",
      "{'ne01': 4, 'ne02': 5, 'ne03': 4, 'ne04': 12, 'ne05': 3, 'ne06': 3, 'ne07': 5, 'ne08': 3, 'ne09': 11, 'ne10': 5, 'ne11': 3, 'is01': 4, 'is02': 3, 'is04': 5, 'is05': 3, 'is06': 3, 'is07': 3, 'is08': 7, 'py01': 5, 'py02': 4, 'py03': 5, 'py04': 13, 'py05': 4, 'py06': 6, 'py07': 1, 'py08': 5, 'py09': 5, 'py10': 4, 'py11': 4, 'py12': 4, 'ol01': 4, 'ol02': 5, 'ol03': 3, 'ol04': 1, 'ol05': 3, 'ol06': 5, 'ol07': 5, 'ol08': 4, 'ol09': 4, 'ol10': 5, 'ol11': 1, 'ol12': 1, 'ol13': 5, 'ol14': 2}\n",
      "Total refrains: 194\n",
      "Total cantica in triads: 44\n",
      "\n",
      "Strophe Responsion Counts:\n",
      "{'ol01': 8, 'ol02': 10, 'ol03': 6, 'ol04': 2, 'ol05': 6, 'ol06': 10, 'ol07': 10, 'ol08': 8, 'ol09': 8, 'ol10': 10, 'ol11': 2, 'ol12': 2, 'ol13': 10, 'is01': 8, 'is02': 6, 'is03': 8, 'is04': 6, 'is05': 6, 'is06': 6, 'ne01': 8, 'ne03': 8, 'ne05': 6, 'ne06': 6, 'ne07': 10, 'ne08': 6, 'ne10': 10, 'ne11': 6, 'py01': 10, 'py02': 8, 'py03': 10, 'py04': 26, 'py05': 8, 'py07': 2, 'py08': 10, 'py09': 10, 'py10': 8, 'py11': 8}\n",
      "Total refraims: 292\n",
      "Total cantica in strophes: 37\n"
     ]
    }
   ],
   "source": [
    "from src.stats_comp import compatibility_canticum, compatibility_ratios_to_stats\n",
    "\n",
    "# (1) get responsion attribute of all cantica with the same strophicity\n",
    "\n",
    "from lxml import etree\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "def count_canticum_elements(xml_dir):\n",
    "    \"\"\"\n",
    "    Count total number of canticum elements across all XML files in a directory.\n",
    "    \n",
    "    Args:\n",
    "        xml_dir: Path to directory containing XML files\n",
    "    \n",
    "    Returns:\n",
    "        int: Total count of cantica elements\n",
    "    \"\"\"\n",
    "    xml_path = Path(xml_dir)\n",
    "    total_cantica = 0\n",
    "    \n",
    "    # Iterate through all XML files in the directory\n",
    "    for xml_file in xml_path.glob('*.xml'):\n",
    "        try:\n",
    "            tree = etree.parse(str(xml_file))\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Query for all cantica elements\n",
    "            cantica = root.xpath('//canticum')\n",
    "            total_cantica += len(cantica)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {xml_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return total_cantica\n",
    "\n",
    "def count_strophe_responsions(xml_dir):\n",
    "    \"\"\"\n",
    "    Count occurrences of each unique responsion attribute in strophe elements\n",
    "    across all XML files in a directory.\n",
    "    \n",
    "    Args:\n",
    "        xml_dir: Path to directory containing XML files\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with responsion attributes as keys and counts as values\n",
    "    \"\"\"\n",
    "    xml_path = Path(xml_dir)\n",
    "    all_responsions = []\n",
    "    \n",
    "    # Iterate through all XML files in the directory\n",
    "    for xml_file in xml_path.glob('*.xml'):\n",
    "        try:\n",
    "            tree = etree.parse(str(xml_file))\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Query for all strophe elements\n",
    "            strophes = root.xpath('//strophe')\n",
    "            \n",
    "            # Extract responsion attributes\n",
    "            responsions = [strophe.get('responsion') for strophe in strophes]\n",
    "            all_responsions.extend(responsions)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {xml_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Use Counter to create a dict of counts\n",
    "    responsion_counts = dict(Counter(all_responsions))\n",
    "    total = sum(responsion_counts.values())\n",
    "    \n",
    "    return responsion_counts, total\n",
    "\n",
    "triads_dir = 'data/compiled/triads/'\n",
    "strophes_dir = 'data/compiled/strophes/'\n",
    "\n",
    "triad_responsion_counts, triad_total = count_strophe_responsions(triads_dir)\n",
    "triad_cantica_count = count_canticum_elements(triads_dir)\n",
    "strophe_responsion_counts, strophe_total = count_strophe_responsions(strophes_dir)\n",
    "strophe_cantica_count = count_canticum_elements(strophes_dir)\n",
    "\n",
    "print(\"Triad Responsion Counts:\")\n",
    "print(triad_responsion_counts)\n",
    "print(f\"Total refrains: {triad_total}\")\n",
    "print(f\"Total cantica in triads: {triad_cantica_count}\\n\")\n",
    "\n",
    "print(\"Strophe Responsion Counts:\")\n",
    "print(strophe_responsion_counts)\n",
    "print(f\"Total refraims: {strophe_total}\")\n",
    "print(f\"Total cantica in strophes: {strophe_cantica_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75028a88",
   "metadata": {},
   "source": [
    "# Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd29a39",
   "metadata": {},
   "source": [
    "## Single heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c86110",
   "metadata": {},
   "source": [
    "Let's first make a text matrix of the sylls of the first strophe, to have something as a handy reference overlay on the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.utils import get_text_matrix\n",
    "\n",
    "# Print the shape\n",
    "text_matrix, row_lengths = get_text_matrix(\"data/compiled/ht_olympians_triads.xml\", canticum_index=1)\n",
    "num_rows = len(text_matrix)\n",
    "row_lengths = [len(row) for row in text_matrix]\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Length of each row: {row_lengths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a50b8f",
   "metadata": {},
   "source": [
    "Here's a full code for making a heatmap with text overlay, for both the triads and the strophes and antistrophes considered as responding with each other (there's no use heatmapping the epodes, since they are just the lowest part of the triads).\n",
    "\n",
    "Use the `text_overlay=True` boolean to add text; note that the overlay mapping does not work well for songs where resolutions respond with unresolved longs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmaps import make_one_heatmap\n",
    "\n",
    "make_one_heatmap(\"data/compiled/triads/ht_olympians_triads.xml\", \"ol01\", \"Mel. Comp. Heatmap of Olympia 1\", representative_strophe=1, save=False, show=True, dark_mode=True, text_overlay=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c3413",
   "metadata": {},
   "source": [
    "Of course, we want to make individual heatmaps for each and every canticum in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64463d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.utils import get_canticum_ids\n",
    "from heatmaps import canticum_with_at_least_two_strophes, make_one_heatmap\n",
    "\n",
    "###### SETTINGS #######\n",
    "\n",
    "responding_unit = \"strophes\"  # \"triads\", \"strophes\"\n",
    "overlay = True\n",
    "dark = not overlay\n",
    "\n",
    "make_assert = False\n",
    "\n",
    "#######################\n",
    "\n",
    "folder = f\"data/compiled/{responding_unit}/\"\n",
    "\n",
    "if overlay:\n",
    "    out_folder = f\"media/heatmaps/{responding_unit}/text/\"\n",
    "else:\n",
    "    out_folder = f\"media/heatmaps/{responding_unit}/notext/\"\n",
    "\n",
    "groups = [[f\"ht_olympians_{responding_unit}.xml\", \"Olympia\"], [f\"ht_pythians_{responding_unit}.xml\", \"Pythia\"], [f\"ht_nemeans_{responding_unit}.xml\", \"Nemea\"], [f\"ht_isthmians_{responding_unit}.xml\", \"Isthmia\"]]\n",
    "for group in groups:\n",
    "    xml_path = os.path.join(folder, group[0])\n",
    "    responsion_attributes = get_canticum_ids(xml_path)\n",
    "    print(f\"Canticum IDs in {group[1]}: {responsion_attributes}\")\n",
    "\n",
    "    for responsion_attribute in tqdm(responsion_attributes):\n",
    "        if not canticum_with_at_least_two_strophes(xml_path, responsion_attribute):\n",
    "            print(f\"Skipping {responsion_attribute} in {group[1]} (less than 2 strophes).\")\n",
    "            continue\n",
    "        \n",
    "        if responsion_attribute == \"ol02\":\n",
    "            print(f\"Skipping {responsion_attribute} in {group[1]} (known data issue).\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Generating heatmap for {group[1]} with responsion attribute {responsion_attribute}...\")\n",
    "\n",
    "        number = int(responsion_attribute[2:])\n",
    "        if responding_unit == \"strophes\":\n",
    "            title = f\"Mel. Comp. Heatmap of {group[1]} {number} (Strophic-Antistrophic)\"\n",
    "        else:\n",
    "            title = f\"Mel. Comp. Heatmap of {group[1]} {number}\"\n",
    "        make_one_heatmap(xml_path, out_folder, responsion_attribute, title, representative_strophe=1, save=True, show=False, dark_mode=dark, text_overlay=overlay)\n",
    "\n",
    "print(len(os.listdir(out_folder)))\n",
    "if make_assert:\n",
    "    assert len(os.listdir(out_folder)) == 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d5f372",
   "metadata": {},
   "source": [
    "A nice way to compare two heatmaps is to make a gif with Pillow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506cd690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "png_files = [\n",
    "    \"media/plots/heatmaps/is04.png\",\n",
    "    \"media/plots/heatmaps/is04_eric.png\"\n",
    "]\n",
    "\n",
    "frames = [Image.open(f).convert(\"P\", palette=Image.ADAPTIVE, colors=256) for f in png_files]\n",
    "\n",
    "frames[0].save(\n",
    "    \"conj_is04.gif\",\n",
    "    save_all=True,\n",
    "    append_images=frames[1:],\n",
    "    duration=500,  # ms\n",
    "    loop=0,\n",
    "    optimize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f6ca4",
   "metadata": {},
   "source": [
    "### Poster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76998252",
   "metadata": {},
   "source": [
    "A striking aesthetic effect can be achieved by removing all text, a good fit for posters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48783cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from src.stats_comp import compatibility_play, compatibility_canticum\n",
    "\n",
    "#data = compatibility_play('data/compiled/py04.xml')\n",
    "data = compatibility_canticum('data/compiled/triads/ht_isthmians_triads.xml', \"is04\")\n",
    "\n",
    "data_matrix = data\n",
    "\n",
    "num_rows_data = len(data_matrix)\n",
    "max_len_data = max(len(row) for row in data_matrix)\n",
    "\n",
    "# -----------------------------\n",
    "# Pad numeric matrix for heatmap\n",
    "# -----------------------------\n",
    "max_len = max_len_data\n",
    "padded_data = np.full((len(data_matrix), max_len), np.nan)\n",
    "for i, row in enumerate(data_matrix):\n",
    "    padded_data[i, :len(row)] = row\n",
    "\n",
    "# -----------------------------\n",
    "# Plot heatmap (dark mode, no text overlay)\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.heatmap(\n",
    "    padded_data, \n",
    "    cmap=\"viridis\", \n",
    "    mask=np.isnan(padded_data), \n",
    "    cbar=True,\n",
    "    vmax = 1\n",
    ")\n",
    "\n",
    "# Dark background + white labels\n",
    "ax.set_facecolor(\"black\")\n",
    "ax.figure.set_facecolor(\"black\")\n",
    "ax.tick_params(colors=\"white\")  # tick labels\n",
    "ax.xaxis.label.set_color(\"white\")\n",
    "ax.yaxis.label.set_color(\"white\")\n",
    "ax.title.set_color(\"white\")\n",
    "\n",
    "# plt.xlabel(\"Metrical position (resolutions merged)\")\n",
    "# plt.ylabel(\"Line number (Snell-Maehler)\")\n",
    "# plt.title(\"Melodic-Comp. Heatmap of Pythia 4\")\n",
    "# plt.yticks(\n",
    "#     ticks=np.arange(len(data_matrix)) + 0.5,\n",
    "#     labels=np.arange(1, len(data_matrix)+1)\n",
    "# )\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.savefig(\"media/plots/heatmap_notext_invertedcolours_pythia_4_comp.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db5a49a",
   "metadata": {},
   "source": [
    "## Set of heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9041c9b",
   "metadata": {},
   "source": [
    "### Olympians "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a46b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmaps import make_all_heatmaps\n",
    "make_all_heatmaps('data/compiled/triads/ht_olympians_triads.xml', prefix=\"ol\", suptitle=\"Melodic Compatibility Heatmaps - Olympians (triads)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83525bfa",
   "metadata": {},
   "source": [
    "### Isthmians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e57748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmaps import make_all_heatmaps\n",
    "make_all_heatmaps('data/compiled/ht_isthmians_triads.xml', prefix=\"is\", suptitle=\"Melodic Compatibility Heatmaps - Isthmians\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1294f6d7",
   "metadata": {},
   "source": [
    "### Nemeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b224a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmaps import make_all_heatmaps\n",
    "make_all_heatmaps('data/compiled/ht_nemeans_triads.xml', prefix=\"ne\", suptitle=\"Melodic Compatibility Heatmaps - Nemeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6825a77e",
   "metadata": {},
   "source": [
    "### Pythians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmaps import make_all_heatmaps\n",
    "make_all_heatmaps('data/compiled/ht_pythians_triads.xml', prefix=\"py\", suptitle=\"Melodic Compatibility Heatmaps - Pythians\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
