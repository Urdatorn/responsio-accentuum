{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ff3bcb",
   "metadata": {},
   "source": [
    "# Prose baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8cd4dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "ROOT = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb2711",
   "metadata": {},
   "source": [
    "To speed up computation, we preprocess and pickle the source prose corpus once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afba293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from src.baseline import preprocess_and_cache_prose_corpus, PROSE_CACHE_PATH\n",
    "from src.utils.prose import anabasis\n",
    "\n",
    "if not os.path.exists(PROSE_CACHE_PATH):\n",
    "    cache = preprocess_and_cache_prose_corpus(\n",
    "        anabasis,\n",
    "        cache_file=PROSE_CACHE_PATH,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcfe3c7",
   "metadata": {},
   "source": [
    "## 1) Make and compile the prose baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5788aa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 987.40it/s]      | 13/40 [00:00<00:00, 128.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prose baseline for responsion ol01 to /Users/albin/git/responsio-accentuum/data/scan/baselines/triads/prose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:08<00:00, 1143.31it/s]     | 13/40 [00:20<00:00, 128.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prose baseline for responsion ol02 to /Users/albin/git/responsio-accentuum/data/scan/baselines/triads/prose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 2503.62it/s]     | 20/40 [00:30<00:38,  1.92s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prose baseline for responsion ol03 to /Users/albin/git/responsio-accentuum/data/scan/baselines/triads/prose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 4766.34it/s]▎    | 21/40 [00:37<00:43,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prose baseline for responsion ol05 to /Users/albin/git/responsio-accentuum/data/scan/baselines/triads/prose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:09<00:00, 1102.70it/s]▎    | 21/40 [00:50<00:43,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prose baseline for responsion ol06 to /Users/albin/git/responsio-accentuum/data/scan/baselines/triads/prose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:08<00:00, 1231.35it/s]▊    | 23/40 [00:57<01:03,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prose baseline for responsion ol07 to /Users/albin/git/responsio-accentuum/data/scan/baselines/triads/prose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing olympians scanned prose baselines:  57%|█████▊    | 23/40 [01:10<00:52,  3.06s/it]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbaseline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_all_prose_baselines\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mmake_all_prose_baselines\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtriads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomizations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10_000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/responsio-accentuum/src/baseline.py:117\u001b[39m, in \u001b[36mmake_all_prose_baselines\u001b[39m\u001b[34m(responding_unit, randomizations)\u001b[39m\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m canticum_with_at_least_two_strophes(xml_path, responsion_id):\n\u001b[32m    115\u001b[39m             \u001b[38;5;66;03m#print(f\"Skipping {responsion_id} in {collection} (less than 2 strophes).\")\u001b[39;00m\n\u001b[32m    116\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m         \u001b[43mmake_prose_baseline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponsion_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomizations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandomizations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m baseline_scan_dir = ROOT / \u001b[33m\"\u001b[39m\u001b[33mdata/scan/baselines/triads/prose/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    120\u001b[39m baseline_compiled_dir = ROOT / \u001b[33m\"\u001b[39m\u001b[33mdata/compiled/baselines/triads/prose/\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/responsio-accentuum/src/baseline.py:295\u001b[39m, in \u001b[36mmake_prose_baseline\u001b[39m\u001b[34m(xml_file, responsion_id, debug, cache_file, randomizations)\u001b[39m\n\u001b[32m    293\u001b[39m filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbaseline_prose_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponsion_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.xml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    294\u001b[39m filepath = outdir / filename\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m \u001b[43mdummy_xml_strophe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrophe_samples_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m# Debug first sample only\u001b[39;00m\n\u001b[32m    299\u001b[39m     first_key = \u001b[38;5;28mlist\u001b[39m(strophe_samples_dict.keys())[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/responsio-accentuum/src/baseline.py:1422\u001b[39m, in \u001b[36mdummy_xml_strophe\u001b[39m\u001b[34m(strophe_sample_lists_dict, outfile, type)\u001b[39m\n\u001b[32m   1417\u001b[39m     xml_content += \u001b[33m'''\u001b[39m\u001b[33m    </body>\u001b[39m\n\u001b[32m   1418\u001b[39m \u001b[33m  </text>\u001b[39m\n\u001b[32m   1419\u001b[39m \u001b[33m</TEI>\u001b[39m\u001b[33m'''\u001b[39m\n\u001b[32m   1421\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(outfile, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml_content\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "from baseline import make_all_prose_baselines\n",
    "\n",
    "make_all_prose_baselines(\"triads\", randomizations=10_000)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4372dc4d",
   "metadata": {},
   "source": [
    "## 2. Compute stats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce58dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [08:09, 12.23s/it]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio done.\n",
      "0.7502304988332094\n"
     ]
    }
   ],
   "source": [
    "from src.stats_comp import compatibility_corpus, compatibility_ratios_to_stats\n",
    "\n",
    "all_comp_ratios_bl = compatibility_corpus('data/compiled/baselines/triads/prose')\n",
    "print(\"Ratio done.\")\n",
    "corpus_comp_stat_bl = compatibility_ratios_to_stats(all_comp_ratios_bl)\n",
    "print(corpus_comp_stat_bl)\n",
    "\n",
    "# with open(\"results.py\", \"a\") as f:\n",
    "#     f.write(\"\\n\")\n",
    "#     f.write()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comp_ratios = compatibility_corpus('data/compiled/triads/')\n",
    "corpus_comp_stat = compatibility_ratios_to_stats(all_comp_ratios)\n",
    "print(corpus_comp_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8309d1a",
   "metadata": {},
   "source": [
    "## 3. Make heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2efa924",
   "metadata": {},
   "source": [
    "To show the strongest tendencies, we can make heatmaps showing the mean of all 100 baselines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3aaff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.heatmaps import make_one_heatmap_per_100_baselines\n",
    "\n",
    "###### SETTINGS #######\n",
    "\n",
    "responding_unit = \"triads\"  # \"triads\", \"strophes\"\n",
    "overlay = False\n",
    "dark = not overlay\n",
    "\n",
    "#######################\n",
    "\n",
    "in_folder = f\"data/compiled/baselines/{responding_unit}/prose/\"\n",
    "out_folder = f\"media/heatmaps/{responding_unit}/baselines/\"\n",
    "\n",
    "xmls = os.listdir(in_folder)\n",
    "xmls = [f for f in xmls if f.endswith(\".xml\")]\n",
    "\n",
    "for xml_file in tqdm(xmls):\n",
    "\n",
    "    print(xml_file)\n",
    "    responsion_id = xml_file.split('_')[2].replace('.xml', '')\n",
    "    xml_path = os.path.join(in_folder, xml_file)\n",
    "\n",
    "    if responding_unit == \"strophes\":\n",
    "        title = f\"Baseline Heatmap of {responsion_id} (Strophic-Antistrophic)\"\n",
    "    else:\n",
    "        title = f\"Baseline Heatmap of {responsion_id} (Triadic)\"\n",
    "    make_one_heatmap_per_100_baselines(xml_path, out_folder, responsion_id, title, save=True, show=False, dark_mode=dark)\n",
    "\n",
    "print(len(os.listdir(out_folder)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e69560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.utils import get_canticum_ids\n",
    "from src.heatmaps import canticum_with_at_least_two_strophes, make_one_heatmap\n",
    "\n",
    "###### SETTINGS #######\n",
    "\n",
    "responding_unit = \"triads\"  # \"triads\", \"strophes\"\n",
    "overlay = False\n",
    "dark = not overlay\n",
    "\n",
    "#######################\n",
    "\n",
    "in_folder = f\"data/compiled/baselines/{responding_unit}/prose/\"\n",
    "out_folder = f\"media/heatmaps/{responding_unit}/baselines/\"\n",
    "\n",
    "xmls = os.listdir(in_folder)\n",
    "xmls = [f for f in xmls if f.endswith(\".xml\")]\n",
    "\n",
    "for xml_file in xmls:\n",
    "\n",
    "    xml_path = os.path.join(in_folder, xml_file)\n",
    "\n",
    "    responsion_attributes = get_canticum_ids(xml_path)\n",
    "\n",
    "    for responsion_attribute in tqdm(responsion_attributes):\n",
    "        if not canticum_with_at_least_two_strophes(xml_path, responsion_attribute):\n",
    "            print(f\"Skipping {responsion_attribute} in {group[1]} (less than 2 strophes).\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Generating baseline heatmap for {responsion_attribute}...\")\n",
    "\n",
    "        group = \"\"\n",
    "        if responsion_attribute.startswith(\"ol\"):\n",
    "            group = \"Olympia\"\n",
    "        elif responsion_attribute.startswith(\"py\"):\n",
    "            group = \"Pythia\"\n",
    "        elif responsion_attribute.startswith(\"ne\"):\n",
    "            group = \"Nemea\"\n",
    "        elif responsion_attribute.startswith(\"is\"):\n",
    "            group = \"Isthmia\"\n",
    "\n",
    "        number = int(responsion_attribute[2:])\n",
    "\n",
    "        if responding_unit == \"strophes\":\n",
    "            title = f\"Baseline Heatmap of {group} {number} (Strophic-Antistrophic)\"\n",
    "        else:\n",
    "            title = f\"Baseline Heatmap of {group} {number}\"\n",
    "        make_one_heatmap(xml_path, out_folder, responsion_attribute, title, representative_strophe=1, save=True, show=False, dark_mode=dark, text_overlay=overlay)\n",
    "\n",
    "print(len(os.listdir(out_folder)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe18881d",
   "metadata": {},
   "source": [
    "## Gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b95af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "png_files = [\n",
    "    \"media/plots/heatmap_notext_invertedcolours_pythia_4_comp.png\",\n",
    "    \"media/plots/heatmap_notext_invertedcolours_pythia_4_comp_baseline.png\"\n",
    "]\n",
    "\n",
    "frames = [Image.open(f).convert(\"P\", palette=Image.ADAPTIVE, colors=256) for f in png_files]\n",
    "\n",
    "frames[0].save(\n",
    "    \"baseline_animated_py04_PIL.gif\",\n",
    "    save_all=True,\n",
    "    append_images=frames[1:],\n",
    "    duration=500,  # ms\n",
    "    loop=0,\n",
    "    optimize=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
